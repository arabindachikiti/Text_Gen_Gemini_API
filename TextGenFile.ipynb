{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9707f9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb940b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, imagine you're having a chat with a computer brain, like me!\n",
      "\n",
      "The \"Model Context Protocol\" is just a fancy way of saying:\n",
      "\n",
      "**\"How the computer brain remembers and uses what we've already talked about in *this specific conversation* to understand what you say next and give you a good answer.\"**\n",
      "\n",
      "Think of it like this:\n",
      "\n",
      "1.  **Your Memory in a Chat:** When you're chatting with a friend, you don't re-introduce yourself or explain everything from the beginning every time you send a message. You remember what you've just talked about, right? If your friend says, \"Did you finish that homework?\", and you reply \"Yes, it was tricky!\", your friend knows \"it\" means the homework because you just talked about it.\n",
      "2.  **The Computer Brain's \"Memory\" (Context):** The AI needs to do the same thing! It needs to remember the recent messages in our chat. This \"memory\" of the recent conversation is called the **\"Context\"**.\n",
      "3.  **The \"Protocol\" (The Rules):** The \"Protocol\" is simply the *way* the AI uses this \"Context\" (the chat memory). When you send a new message, the AI doesn't just read that one message. It looks at your new message PLUS the recent messages *before* it. It uses this combination to figure out what you mean and how to respond.\n",
      "\n",
      "**Why is it important?**\n",
      "\n",
      "*   **Understanding:** It helps the AI understand questions that refer back to something said earlier (like \"Tell me more about *that*\").\n",
      "*   **Keeping Track:** It keeps the conversation flowing logically.\n",
      "*   **Giving Better Answers:** It helps the AI give answers that are relevant to what we've *already* discussed.\n",
      "\n",
      "**Think of it like:**\n",
      "\n",
      "*   Taking notes during a lesson: The notes (context) help you understand the next thing the teacher says.\n",
      "*   Reading a book: You need to remember what happened in previous chapters (context) to understand the current one.\n",
      "\n",
      "**Important Note (The Limit):**\n",
      "\n",
      "This \"memory\" (context) isn't infinite! The AI can only remember so much of the conversation history at one time. If a chat goes on for a *very long time*, the AI might start to \"forget\" the *very first* things you talked about because they get pushed out by the new messages. It's like your notebook getting full â€“ you can only fit so many notes in it.\n",
      "\n",
      "**So, in simple terms for a school student:**\n",
      "\n",
      "The Model Context Protocol is just **how the computer brain uses the recent memory of our chat to understand you and keep the conversation making sense.**\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key='AIzaSyAwXQIVa_3KlCjC8w41Ic3LhEm94_pHKrs')\n",
    "#model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-preview-04-17')\n",
    "response = model.generate_content('What is the model context protocol to a school student?')\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
